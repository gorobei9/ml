{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prd(l):\n",
    "    p = 1\n",
    "    for i in l:\n",
    "        p *= int(i)\n",
    "    return p\n",
    "\n",
    "def layerStrs(l):\n",
    "    c = l.get_config()\n",
    "    #print(l.__class__.__name__, c)\n",
    "    name = c.get('name', '')\n",
    "    unit = l.__class__.__name__\n",
    "    act = c.get('activation', '')\n",
    "    size = c.get('kernel_size', '')\n",
    "    if not size:\n",
    "        size = c.get('pool_size', '')\n",
    "    if not size:\n",
    "        size = c.get('rate', '')\n",
    "    iShape = l.input_shape[1:]\n",
    "    oShape = l.output_shape[1:]\n",
    "    nParam = sum( [ prd(w.shape) for w in l.weights ] )\n",
    "    nData = prd(oShape)\n",
    "    return [name, unit, act, size, iShape, oShape, nParam, nData] \n",
    "\n",
    "def prn(self):\n",
    "    strs = ['|Layer|Name|Unit|Activation|Size|iShape|oShape|nParam|nData|',\n",
    "            '|-----|-----|----|----|------|------|------|-----|']\n",
    "    tp = 0\n",
    "    for i,l in enumerate(self.layers):\n",
    "        f = tuple([i+1,]+layerStrs(l))\n",
    "        strs.append('|%s|%s|%s|%s|%s|%s|%s|%s|%s|' % f )\n",
    "        tp += f[7]\n",
    "    t = '\\n'.join(strs)\n",
    "    display(Markdown(t))\n",
    "    print(tp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelnaunton/anaconda/envs/py36-test/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/michaelnaunton/anaconda/envs/py36-test/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/michaelnaunton/anaconda/envs/py36-test/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "|Layer|Name|Unit|Activation|Size|iShape|oShape|nParam|nData|\n",
       "|-----|-----|----|----|------|------|------|-----|\n",
       "|1|conv2d_1|Conv2D|linear|(7, 7)|(28, 28, 1)|(22, 22, 27)|1323|13068|\n",
       "|2|dropout_1|Dropout||0.05|(22, 22, 27)|(22, 22, 27)|0|13068|\n",
       "|3|max_pooling2d_1|MaxPooling2D||(9, 9)|(22, 22, 27)|(4, 4, 27)|0|432|\n",
       "|4|conv2d_2|Conv2D|relu|(1, 1)|(4, 4, 27)|(4, 4, 14)|378|224|\n",
       "|5|flatten_1|Flatten|||(4, 4, 14)|(224,)|0|224|\n",
       "|6|dropout_2|Dropout||0.05|(224,)|(224,)|0|224|\n",
       "|7|dense_1|Dense|softmax||(224,)|(10,)|2250|10|"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3951\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/60\n",
      "60000/60000 [==============================] - 49s 824us/step - loss: 0.3863 - acc: 0.8865 - val_loss: 0.1086 - val_acc: 0.9677\n",
      "Epoch 2/60\n",
      "60000/60000 [==============================] - 51s 848us/step - loss: 0.1231 - acc: 0.9625 - val_loss: 0.0920 - val_acc: 0.9712\n",
      "Epoch 3/60\n",
      "60000/60000 [==============================] - 44s 731us/step - loss: 0.0974 - acc: 0.9703 - val_loss: 0.0638 - val_acc: 0.9792\n",
      "Epoch 4/60\n",
      "60000/60000 [==============================] - 39s 654us/step - loss: 0.0824 - acc: 0.9747 - val_loss: 0.0572 - val_acc: 0.9824\n",
      "Epoch 5/60\n",
      "60000/60000 [==============================] - 38s 641us/step - loss: 0.0743 - acc: 0.9769 - val_loss: 0.0515 - val_acc: 0.9843\n",
      "Epoch 6/60\n",
      "60000/60000 [==============================] - 42s 707us/step - loss: 0.0681 - acc: 0.9792 - val_loss: 0.0498 - val_acc: 0.9846\n",
      "Epoch 7/60\n",
      "60000/60000 [==============================] - 45s 753us/step - loss: 0.0645 - acc: 0.9805 - val_loss: 0.0473 - val_acc: 0.9854\n",
      "Epoch 8/60\n",
      "60000/60000 [==============================] - 46s 767us/step - loss: 0.0599 - acc: 0.9814 - val_loss: 0.0465 - val_acc: 0.9865\n",
      "Epoch 9/60\n",
      "60000/60000 [==============================] - 45s 756us/step - loss: 0.0565 - acc: 0.9825 - val_loss: 0.0522 - val_acc: 0.9829\n",
      "Epoch 10/60\n",
      "60000/60000 [==============================] - 44s 736us/step - loss: 0.0541 - acc: 0.9831 - val_loss: 0.0402 - val_acc: 0.9869\n",
      "Epoch 11/60\n",
      "60000/60000 [==============================] - 45s 745us/step - loss: 0.0518 - acc: 0.9835 - val_loss: 0.0440 - val_acc: 0.9865\n",
      "Epoch 12/60\n",
      "60000/60000 [==============================] - 45s 744us/step - loss: 0.0503 - acc: 0.9839 - val_loss: 0.0468 - val_acc: 0.9852\n",
      "Epoch 13/60\n",
      "60000/60000 [==============================] - 41s 691us/step - loss: 0.0481 - acc: 0.9847 - val_loss: 0.0374 - val_acc: 0.9885\n",
      "Epoch 14/60\n",
      "60000/60000 [==============================] - 40s 672us/step - loss: 0.0468 - acc: 0.9851 - val_loss: 0.0372 - val_acc: 0.9888\n",
      "Epoch 15/60\n",
      "60000/60000 [==============================] - 42s 693us/step - loss: 0.0453 - acc: 0.9859 - val_loss: 0.0421 - val_acc: 0.9872\n",
      "Epoch 16/60\n",
      "60000/60000 [==============================] - 42s 693us/step - loss: 0.0442 - acc: 0.9863 - val_loss: 0.0355 - val_acc: 0.9889\n",
      "Epoch 17/60\n",
      "60000/60000 [==============================] - 42s 697us/step - loss: 0.0428 - acc: 0.9863 - val_loss: 0.0407 - val_acc: 0.9879\n",
      "Epoch 18/60\n",
      "60000/60000 [==============================] - 42s 697us/step - loss: 0.0411 - acc: 0.9871 - val_loss: 0.0371 - val_acc: 0.9891\n",
      "Epoch 19/60\n",
      "60000/60000 [==============================] - 41s 681us/step - loss: 0.0404 - acc: 0.9870 - val_loss: 0.0435 - val_acc: 0.9866\n",
      "Epoch 20/60\n",
      "60000/60000 [==============================] - 43s 715us/step - loss: 0.0394 - acc: 0.9875 - val_loss: 0.0420 - val_acc: 0.9863\n",
      "Epoch 21/60\n",
      "60000/60000 [==============================] - 40s 670us/step - loss: 0.0392 - acc: 0.9873 - val_loss: 0.0344 - val_acc: 0.9894\n",
      "Epoch 22/60\n",
      "60000/60000 [==============================] - 35s 587us/step - loss: 0.0387 - acc: 0.9875 - val_loss: 0.0371 - val_acc: 0.9886\n",
      "Epoch 23/60\n",
      "60000/60000 [==============================] - 34s 560us/step - loss: 0.0382 - acc: 0.9877 - val_loss: 0.0340 - val_acc: 0.9897\n",
      "Epoch 24/60\n",
      "60000/60000 [==============================] - 36s 596us/step - loss: 0.0375 - acc: 0.9879 - val_loss: 0.0351 - val_acc: 0.9896\n",
      "Epoch 25/60\n",
      "60000/60000 [==============================] - 35s 582us/step - loss: 0.0366 - acc: 0.9885 - val_loss: 0.0377 - val_acc: 0.9893\n",
      "Epoch 26/60\n",
      "60000/60000 [==============================] - 36s 602us/step - loss: 0.0352 - acc: 0.9889 - val_loss: 0.0328 - val_acc: 0.9909\n",
      "Epoch 27/60\n",
      "60000/60000 [==============================] - 40s 674us/step - loss: 0.0354 - acc: 0.9889 - val_loss: 0.0346 - val_acc: 0.9891\n",
      "Epoch 28/60\n",
      "60000/60000 [==============================] - 41s 687us/step - loss: 0.0341 - acc: 0.9892 - val_loss: 0.0316 - val_acc: 0.9903\n",
      "Epoch 29/60\n",
      "60000/60000 [==============================] - 42s 694us/step - loss: 0.0339 - acc: 0.9894 - val_loss: 0.0367 - val_acc: 0.9890\n",
      "Epoch 30/60\n",
      "60000/60000 [==============================] - 38s 626us/step - loss: 0.0322 - acc: 0.9898 - val_loss: 0.0359 - val_acc: 0.9896\n",
      "Epoch 31/60\n",
      "60000/60000 [==============================] - 37s 623us/step - loss: 0.0325 - acc: 0.9898 - val_loss: 0.0347 - val_acc: 0.9898\n",
      "Epoch 32/60\n",
      "60000/60000 [==============================] - 36s 607us/step - loss: 0.0319 - acc: 0.9895 - val_loss: 0.0338 - val_acc: 0.9898\n",
      "Epoch 33/60\n",
      "60000/60000 [==============================] - 35s 585us/step - loss: 0.0322 - acc: 0.9897 - val_loss: 0.0334 - val_acc: 0.9908\n",
      "Epoch 34/60\n",
      "60000/60000 [==============================] - 39s 648us/step - loss: 0.0313 - acc: 0.9899 - val_loss: 0.0332 - val_acc: 0.9906\n",
      "Epoch 35/60\n",
      "60000/60000 [==============================] - 42s 695us/step - loss: 0.0306 - acc: 0.9903 - val_loss: 0.0359 - val_acc: 0.9892\n",
      "Epoch 36/60\n",
      "60000/60000 [==============================] - 42s 697us/step - loss: 0.0306 - acc: 0.9901 - val_loss: 0.0322 - val_acc: 0.9904\n",
      "Epoch 37/60\n",
      "60000/60000 [==============================] - 39s 655us/step - loss: 0.0304 - acc: 0.9904 - val_loss: 0.0360 - val_acc: 0.9898\n",
      "Epoch 38/60\n",
      "60000/60000 [==============================] - 39s 658us/step - loss: 0.0290 - acc: 0.9910 - val_loss: 0.0359 - val_acc: 0.9893\n",
      "Epoch 39/60\n",
      "60000/60000 [==============================] - 36s 602us/step - loss: 0.0294 - acc: 0.9904 - val_loss: 0.0322 - val_acc: 0.9910\n",
      "Epoch 40/60\n",
      "60000/60000 [==============================] - 39s 647us/step - loss: 0.0279 - acc: 0.9910 - val_loss: 0.0356 - val_acc: 0.9900\n",
      "Epoch 41/60\n",
      "60000/60000 [==============================] - 42s 694us/step - loss: 0.0292 - acc: 0.9907 - val_loss: 0.0324 - val_acc: 0.9913\n",
      "Epoch 42/60\n",
      "60000/60000 [==============================] - 35s 577us/step - loss: 0.0277 - acc: 0.9911 - val_loss: 0.0311 - val_acc: 0.9919\n",
      "Epoch 43/60\n",
      "60000/60000 [==============================] - 41s 691us/step - loss: 0.0283 - acc: 0.9909 - val_loss: 0.0394 - val_acc: 0.9895\n",
      "Epoch 44/60\n",
      "60000/60000 [==============================] - 40s 665us/step - loss: 0.0281 - acc: 0.9912 - val_loss: 0.0309 - val_acc: 0.9913\n",
      "Epoch 45/60\n",
      "60000/60000 [==============================] - 38s 633us/step - loss: 0.0274 - acc: 0.9908 - val_loss: 0.0335 - val_acc: 0.9909\n",
      "Epoch 46/60\n",
      "60000/60000 [==============================] - 42s 697us/step - loss: 0.0276 - acc: 0.9914 - val_loss: 0.0320 - val_acc: 0.9908\n",
      "Epoch 47/60\n",
      "60000/60000 [==============================] - 47s 776us/step - loss: 0.0265 - acc: 0.9913 - val_loss: 0.0342 - val_acc: 0.9901\n",
      "Epoch 48/60\n",
      "60000/60000 [==============================] - 47s 778us/step - loss: 0.0272 - acc: 0.9911 - val_loss: 0.0330 - val_acc: 0.9909\n",
      "Epoch 49/60\n",
      "60000/60000 [==============================] - 38s 627us/step - loss: 0.0269 - acc: 0.9914 - val_loss: 0.0364 - val_acc: 0.9899\n",
      "Epoch 50/60\n",
      "60000/60000 [==============================] - 41s 682us/step - loss: 0.0254 - acc: 0.9917 - val_loss: 0.0340 - val_acc: 0.9908\n",
      "Epoch 51/60\n",
      "60000/60000 [==============================] - 45s 752us/step - loss: 0.0259 - acc: 0.9916 - val_loss: 0.0310 - val_acc: 0.9916\n",
      "Epoch 52/60\n",
      "60000/60000 [==============================] - 44s 739us/step - loss: 0.0254 - acc: 0.9919 - val_loss: 0.0375 - val_acc: 0.9898\n",
      "Epoch 53/60\n",
      "60000/60000 [==============================] - 46s 766us/step - loss: 0.0246 - acc: 0.9922 - val_loss: 0.0320 - val_acc: 0.9907\n",
      "Epoch 54/60\n",
      "60000/60000 [==============================] - 43s 710us/step - loss: 0.0243 - acc: 0.9922 - val_loss: 0.0348 - val_acc: 0.9908\n",
      "Epoch 55/60\n",
      "60000/60000 [==============================] - 43s 723us/step - loss: 0.0242 - acc: 0.9922 - val_loss: 0.0414 - val_acc: 0.9889\n",
      "Epoch 56/60\n",
      "60000/60000 [==============================] - 46s 760us/step - loss: 0.0246 - acc: 0.9918 - val_loss: 0.0384 - val_acc: 0.9893\n",
      "Epoch 57/60\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0241 - acc: 0.9924 - val_loss: 0.0348 - val_acc: 0.9901\n",
      "Epoch 58/60\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.0245 - acc: 0.9921 - val_loss: 0.0327 - val_acc: 0.9907\n",
      "Epoch 59/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 54s 894us/step - loss: 0.0237 - acc: 0.9919 - val_loss: 0.0314 - val_acc: 0.9918\n",
      "Epoch 60/60\n",
      "60000/60000 [==============================] - 50s 827us/step - loss: 0.0236 - acc: 0.9925 - val_loss: 0.0308 - val_acc: 0.9917\n",
      "Test loss: 0.0307828644287074\n",
      "Test accuracy: 0.9917\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 60\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(27, kernel_size=(7, 7), input_shape=input_shape, use_bias=0,))\n",
    "model.add(Dropout(.05))\n",
    "model.add(MaxPooling2D(pool_size=(9, 9), strides=4))\n",
    "model.add(Conv2D(14, kernel_size=(1, 1), activation='relu', use_bias=0)) \n",
    "model.add(Flatten())\n",
    "model.add(Dropout(.05))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "prn(model) # just print a table of the model + param coubnt.\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
